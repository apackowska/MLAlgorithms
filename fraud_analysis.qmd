```{r}
library(caret)
library(rattle) 
library(mlbench) 
library(dplyr)
library(ggplot2)
library(VIM)
library(ada)
library(caret)
library(rattle)
library(MLeval)
library(cluster)
library(factoextra)
```

```{r}
data = read.csv("/Users/ania/Desktop/credit_data.csv")
data <- data[,2:length(data)]
length(data)
summary(data)
str(data)
head(data)
```


```{r}
nrow(data)
```

```{r}
nearZeroVar(data)
```

```{r}
correlation =cor(data[,c(1,7,8)])
correlation
```

```{r}
sum(is.na(data))
```
```{r}
colSums(is.na(data))
```


```{r}
colSums(is.na(data))/ nrow(data) * 100
```
```{r}
sum(complete.cases(data))
```


```{r}
df <-
  data %>%
  select(-"Checking.account")
sum(complete.cases(df))
head(df)
```
```{r}
df2 <-
  data %>%
  select(-"Saving.accounts")
sum(complete.cases(df2))
head(df2)
```
```{r}
df3 <- 
  df %>%
  select(-"Saving.accounts")
sum(complete.cases(df3))
head(df3)
```

```{r}
# hot deck imputation with knn method for missing values
df <- kNN(data, k = 5, variable = "Saving.accounts")
df
```
```{r}
df <- 
  df %>%
  select(-c("Checking.account", "Saving.accounts_imp"))
head(df)
```
```{r}
sum(is.na(df))
```


```{r}
ggplot(data,
       aes(x = Credit.amount,
           y = Checking.account)) +
 geom_point()
```
```{r}
ggplot(data,
       aes(x = Credit.amount,
           y = Saving.accounts)) +
 geom_point()
```
```{r}
chisq.test(table(data$Saving.accounts, data$Checking.account))
```

```{r}
vis_miss(data)
```



```{r}
ggplot(data = df, aes(x = Risk)) + 
  geom_bar(fill= "skyblue") +
  geom_text(stat = "count", aes(label = ..count..), vjust = 0.5) +
  labs(title = "Bar Plot of applicant types", x = "Type of applicant", y = "Count")
```



```{r}
ggplot(df, aes(x=Credit.amount)) +
  geom_histogram()+ 
  labs(title = "Histogram of credit amount", x= "Amount of credit")
```
```{r}
ggplot(df, aes(x=Credit.amount))+
  geom_histogram(color="black", fill="white")+
  facet_wrap(.~Purpose, ncol=4, scales ="free") +
  theme(strip.background = element_rect(colour="black", fill="white",
                                       size=1.5, linetype="solid")) +
  theme(axis.text.x=element_text(angle = 90)) +
  labs(x="Credit amount", y = "Count", title =  "Distribution of credit amount by purpose")
```
```{r}
ggplot(df, aes(x=Job))+
  geom_histogram(color="black", fill="white")+
  facet_wrap(.~Risk, ncol=2, scales ="free") +
  theme(strip.background = element_rect(colour="black", fill="white",
                                       size=1.5, linetype="solid")) +
  theme(axis.text.x=element_text(angle = 90)) +
  labs(x="Job", y = "Count", title =  "Distribution of applicants' types by job")
```



```{r}
ggplot(df, aes(x = Risk, y = Credit.amount)) +
  geom_boxplot() +
  labs(title =  "Box Plot of Credit.amount against Risk") +
  stat_summary(fun.y = "median", geom = "text", aes(label = round(..y.., 2)),
               position = position_dodge(0.75), vjust = -0.5, show.legend = FALSE)
```

```{r}
ggplot(df, aes(x = Risk, y = Duration)) +
  geom_boxplot() +
  labs(title =  "Box Plot of Duration against Risk")+
  stat_summary(fun.y = "median", geom = "text", aes(label = round(..y.., 2)),
               position = position_dodge(0.75), vjust = -0.5, show.legend = FALSE)
```

```{r}
ggplot(df, aes(x = Risk, y = Age)) +
  geom_boxplot() +
  labs(title =  "Box Plot of Age against Risk") +
  stat_summary(fun.y = "median", geom = "text", aes(label = round(..y.., 2)),
               position = position_dodge(0.75), vjust = -0.5, show.legend = FALSE)
```


```{r}
ggplot(df, aes(Risk, Credit.amount, color=Housing)) +
  geom_point() +
  labs(title =  "Scatter Plot of Credit.amount against Risk with types of Housing")+
  stat_summary(fun.y = "median", geom = "text", aes(label = round(..y.., 2)),
               position = position_dodge(0.75), vjust = -0.5, show.legend = FALSE)
```

```{r}
ggplot(df, aes(x = Housing, fill = Risk)) +
  geom_bar() +
  labs(title = "Stacked Bar Chart of Risk and Housing",
       x = "Housing",
       y = "Count") +
  theme_minimal()
```

```{r}
# reference class is positive
class(df$Risk)
df$Risk <- as.factor(df$Risk)
df$Risk=relevel(df$Risk, ref="good")
```


```{r}
# splitting
index = createDataPartition(df$Risk, p = 0.7, list=F) # first parameter is the target variable
train = df[index,]
test = df[-index,]
```



```{r}
# tree
tree= train(Risk~., data=train, method="rpart",
             tuneGrid = expand.grid(cp=seq(0.1,0.5, by=0.1)),
             trControl = trainControl(method="cv", number=10))
tree
```


```{r}
tree$finalModel
pred_rpart = predict(tree, test)
confusionMatrix(pred_rpart, test$Risk)
```


```{r}
tree_auc = train(Risk~., data=train, method="rpart",
             tuneGrid = expand.grid(cp=seq(0.1,0.5, by=0.1)),
             trControl = trainControl(method="cv", number=10,
                    classProbs = TRUE, summaryFunction = twoClassSummary,
                    savePredictions = TRUE))
tree_auc
```
```{r}
X = evalm(tree_auc, gnames = "tree")
```

```{r}
# test set evaluation
# make predictions
pred_tree_class = predict(tree_auc, newdata=test)
pred_tree_prob = predict(tree_auc, newdata=test, type = "prob")
```

```{r}
# confusiun matrix
confusionMatrix(pred_tree_class,test$Risk)
```
```{r}
# add a column
pred_tree_prob$obs = test$Risk
x=evalm(pred_tree_prob)
```
```{r}
lift = lift(test$Risk~pred_tree_prob$bad)
ggplot(lift, values = 60)
# compare actual values with predicion, which is positive probability
# to cover 60% of all bad cases, we need to test about the same amount of cases, meaning the model is very bad at predicting
```

```{r}
numeric_data <- scale(df[,c(1,6,7)])
fviz_nbclust(numeric_data, kmeans, method = "wss")
```

```{r}
fviz_nbclust(numeric_data, kmeans, method='silhouette')
```


```{r}
# knn
knnfit = train(Risk~., data=train, method = "knn", preProcess = c("center", "scale"),
               tuneGrid = expand.grid(k=c(1:3)),
               trControl =  trainControl(method = "cv", number=10))
knnfit
```
```{r}
pred_knn = predict(knnfit, test)
```

```{r}
# calculate performance metrics based on predictions and actual outcomes from a model
postResample(pred_knn, test$Risk)
```

```{r}
# svm
svm_tune <- train(data=train, Risk~. , method="svmLinear", 
                  tuneGrid =expand.grid(C = c(seq(0.1,1,by = 0.1))), 
                  trControl =  trainControl(method = "cv", number=10))
svm_tune
```
```{r}
svm_auc = train(data=train, Risk~. , method="svmLinear", 
                  tuneGrid =expand.grid(C = c(seq(0.1,1,by = 0.1))), 
                  trControl =  trainControl(method = "cv", number=10,
                    classProbs = TRUE, summaryFunction = twoClassSummary,
                    savePredictions = TRUE))
svm_auc
```
```{r}
X = evalm(svm_auc)
```
```{r}
# test set evaluation
# make predictions
pred_svm_class = predict(svm_auc, newdata=test)
pred_svm_prob = predict(svm_auc, newdata=test, type = "prob")
```

```{r}
confusionMatrix(pred_svm_class, test$Risk)
```
```{r}
pred_svm_prob$obs = test$Risk
```
```{r}
# ROC curver on test set
x=evalm(pred_svm_prob)
```
```{r}
# logistic regression
logistic_tune = train(data=train, Risk~. , method="glmnet", preProcess =c("center","scale"),
                      tuneGrid = expand.grid(lambda = 0.04 ,alpha = c(seq(0.1, 1, by= 0.1))), 
                  trControl =  trainControl(method = "cv", number=10))
logistic_tune
```
```{r}
logistic_auc = train(data=train, Risk~. , method="glmnet", preProcess =c("center","scale"),
                      tuneGrid = expand.grid(lambda = 0.04 ,alpha = c(seq(0.1, 1, by= 0.1))), 
trControl =  trainControl(method = "cv", number=10,
                    classProbs = TRUE, summaryFunction = twoClassSummary,
                    savePredictions = TRUE))
logistic_auc
```
```{r}
X = evalm(logistic_auc)
```


```{r}
pred_logistic = predict(logistic_tune, test)
confusionMatrix(pred_logistic, test$Risk)
```
```{r}
# test set evaluation
# make predictions
pred_log_class = predict(logistic_auc, newdata=test)
pred_log_prob = predict(logistic_auc, newdata=test, type = "prob")
```


```{r}
pred_log_prob$obs = test$Risk
x=evalm(pred_log_prob)
```


```{r}
blogistic_tune <- train(data=train, Risk~. , method="LogitBoost", preProcess =c("center","scale"), tuneGrid = expand.grid(nIter = c(seq(10,50,by = 10))), 
                  trControl =  trainControl(method = "cv", number=10))
blogistic_tune
```
```{r}
blogistic_auc = train(data=train, Risk~. , method="LogitBoost", preProcess =c("center","scale"), tuneGrid = expand.grid(nIter = c(seq(10,50,by = 10))), 
                  trControl =  trainControl(method = "cv", number=10,
                    classProbs = TRUE, summaryFunction = twoClassSummary,
                    savePredictions = TRUE))
blogistic_auc
```


```{r}
X = evalm(blogistic_auc)
```


```{r}
pred_logistic_b = predict(blogistic_tune, test)
confusionMatrix(pred_logistic_b, test$Risk)
```

```{r}
# test set evaluation
# make predictions
pred_logb_class = predict(logistic_auc, newdata=test)
pred_logb_prob = predict(logistic_auc, newdata=test, type = "prob")
```

```{r}
pred_logb_prob$obs = test$Risk
x=evalm(pred_logb_prob)
```


